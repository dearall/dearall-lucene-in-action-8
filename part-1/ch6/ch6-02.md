## 6.2 自定义的收集器 Developing a custom Collector ##

大多数的全文搜索应用程序，用户查找通过相关性或者域值排序的 **评分最高的 n 个匹配文档**（top n）。最常用的模型是只有这些返回的 ScoreDoc 可以访问。然而，有些应用场景，用户想要更多精确地控制搜索期间哪些文档应该得以保持。

Lucene 5.0 之前使用抽象基类 Collector 来表示收集器的概念。从 5.0 版本开始，Lucene 重构了 Collector 类，将其切分为 Collector 和 LeafCollector 两个接口，并将命中文档的收集工作转移到对每个索引段上执行，即通过 LeafCollector 接口实现对每个段匹配文档的搜集。而 Collector 接口，主要负责段的切换工作，并确定搜索的整体评分模式。

>LUCENE-5527: [Make the Collector API work per-segment](https://issues.apache.org/jira/browse/LUCENE-5527)

<br/>

通过实现 **LeafCollector** 和 **Collector** 接口，Lucene 接受对每个匹配文档进行完全的自定义的处理。例如，或许想要收集匹配查询每个文档的 ID，也或许利用这些匹配的文档，想要获取其内容或者通过某个外部资源来核对附加信息。

&emsp;&emsp;有可能要使用一个非常大的 numHits 值运行常规的搜索，之后在处理结果。这个方案可以工作，但这是个效率极差的方法，因为这些方法耗费大量的 CPU 计算评分，而这是不必要的，并且还要执行排序，这也是没必要的。利用自定义 Collector 接口实现，可以避免这些耗费成本。

IndexSearcher 通过如下底层 search() 方法利用 Collector 接口执行搜索操作：

- **void search(Query query, Collector results)** 为每个匹配的文档调用 `LeafCollector.collect(int doc)` 方法，实现对匹配结果的收集操作


<br/><br/>
####<font color=green>Collector 接口</font> ####
<br/>

Collector 接口是专家级 API，是用于从搜索收集原始匹配结果的主要途径，并实现排序或对结果自定义过滤，校验，等等。

Lucene 的核心收集器都是实现 Collector 接口并从 **SimpleCollector** 类继承的。SimpleCollector 同时实现了 Collector 接口和 LeafCollector 接口。

应用程序可以完全使用下面这些子类，或者从 TopDocsCollector 抽象类继承，而无需直接实现 Collector 接口：

- **TopDocsCollector** 一个抽象基类，在收集完成之后，根据某些依据，假设要获取 top N 文档
- **TopScoreDocCollector** TopDocsCollector 的具体子类，根据评分值 + docID 进行排序。这个类是 IndexSearcher 不带显式 Sort 参数的 search() 方法内部使用的收集器。它可能是使用最频繁的搜集器。
- **TopFieldCollector** TopDocsCollector 的具体子类，根据指定的 Sort 对象进行排序（sort by field），这个类是 IndexSearcher 带有显式 Sort 参数的 search() 方法内部使用的收集器。
- **TimeLimitingCollector** 封装另一个 Collector 对象，如果搜索操作耗用了太长的时间，终止搜索。
- **PositiveScoresOnlyCollector** 封装另一个 Collector 对象，防止评分小于等于 0（<= 0.0）的命中文档收集到最终结果中


Collector 接口方法定义：

- **LeafCollector getLeafCollector(LeafReaderContext context)** 创建新的 LeafCollector 实例，用于收集给定 LeafReaderContext 环境的匹配文档
- **ScoreMode scoreMode()** 确定该收集器的评分模式，SoreMode 是枚举值，每个枚举值指明要求评分器提供哪些特性：COMPLETE、COMPLETE_NO_SCORES、TOP_DOCS、TOP_DOCS_WITH_SCORES、TOP_SCORES。


<br/>
&emsp;&emsp;&emsp;&emsp;*&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;*&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;*
<br />


<br/><br/>
####<font color=green>LeafCollector 接口</font> ####
<br/>

LeafCollector 是将评分从收集的文档中分离出来的收集器：如果不需要评分，评分计算可以完全略过。对确实需要评分的收集器，应该实现其 `setScorer(Scorable scorer)` 方法，保存传入的 scorer 实例，并在 `collect(int doc)` 方法内调用 `Scorable.score()` 方法，计算当前命中文档的评分。如果收集器多次要求单个匹配文档的评分，应该利用 ScoreCachingWrappingScorer 进行封装。

注意，传入 `collect(int doc)` 方法的 doc 是相对于当前 reader 的，如果收集器需要将传入的 int doc 解析到 Multi*Reader 的 docID 空间，必须通过从最近那次调用 getLeafCollector() 记录的 docBase，重新对 doc 进行变基（re-base it）：`docID = docBase + doc`。下面的示例展示如何 docID 收集到一个 BitSet 中：

```java
 IndexSearcher searcher = new IndexSearcher(indexReader);
 final BitSet bits = new BitSet(indexReader.maxDoc());
 searcher.search(query, new Collector() {

   public LeafCollector getLeafCollector(LeafReaderContext context)
       throws IOException {
     final int docBase = context.docBase;
     return new LeafCollector() {

       // ignore scorer
       public void setScorer(Scorer scorer) throws IOException {
       }

       public void collect(int doc) throws IOException {
         bits.set(docBase + doc);
       }

     };
   }

 });
```

不是所有的收集器都需要对 docID 进行变基，例如，一个简单地计数命中文档总数的收集器就会略过这个操作。

LeafCollector 接口方法定义：

- **void setScorer(Scorable scorer)** 在后续的 `collect(int doc)` 方法调用之前被调用。实现对需要评分的当前文档进行评分，应该将传入的 Scorer 对象保存起来，并且在需要的时候调用 scorer.score() 方法计算评分，它返回当前匹配查询文档的评分值。
- **collect(int doc)** 对每个匹配查询的文档调用一次，参数 int doc 是未变基的（unbased）文档编号。注意：当前索引段的收集器，可以通过抛出 CollectionTerminatedException 来终止收集，在这种情况下，当前 LeafReaderContext 的最后面的那些文档会被忽略掉。而 IndexSearcher 会捕获并吞没这个异常，并继续收集下一个索引段，IndexSearcher 不会再重新向外抛出这个 CollectionTerminatedException 异常。注意：这个方法是在搜索循环的内部调用的。为了良好的搜索性能，这个方法的实现不应该在每个命中文档上调用 `IndexSearcher.doc(int doc)` 或 `IndexReader.document(int doc)`，这样做会拖慢搜索结果几个数量级。
- **default DocIdSetIterator competitiveIterator()** 这是个接口默认方法，可选地返回竞争文档的迭代器。如果收集器的比较器提供了忽略非竞争文档的功能，收集器应该将该方法委托给它们的比较器（comparator）。默认的实现是返回 null 值，被解释为，搜集器提供任何任意的迭代器。


<br/>
&emsp;&emsp;&emsp;&emsp;*&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;*&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;*
<br /><br />


<br/><br/>
<a id="1"></a>

## 6.2.1 Lucene 对搜索结果的收集过程 ##

Collector 和 LeafCollector 接口定义了 Lucene 在搜索时进行交互的 API。与通过 FieldCompartor API 进行自定义排序类似，通过 Collector 和 LeafCollector API 进行高性能命中收集，比我们想象的更加复杂。

&emsp;&emsp;Lucene 所有的核心搜索方法，在底层都使用一个 Collector 实现来执行它们的收集过程。例如，通过相关性排序，使用 TopScoreDocCollector 收集器。通过域值排序，使用 TopFieldCollector 作为收集器。这些类都是 Lucene 核心模块 org.apache.lucene.search 中的具体实现类，用户可以按自己的需要实例化它们。

&emsp;&emsp;在搜索期间，当 Lucene 找到一个匹配的文档时，它调用 LeafCollector 的 `collect(int doc)` 方法。Lucene 并不关心对文档做什么操作，如果需要，完全由 LeafCollector 记录这个匹配。这是搜索操作的热点，因此要确保实现的 collect() 方法只做所要求工作最低限度的操作。

&emsp;&emsp;Lucene 驱动每一次只搜索一个索引段，为了高性能，在每个段切换时通过调用 Collector 的 `LeafCollector 	getLeafCollector(LeafReaderContext context)` 方法来通知 Collector，所提供的 LeafReaderContext 实例是关于这个新的索引段的。Collector 实现需要在这个点上记录新段的 docBase 值，因为 collect(int doc) 方法提供的 docID 是相对于该段的，要获得绝对或者全局的 docID，必须对 doc 进行变基计算，将 docBase 加到 doc 上：`docID = docBase + doc`。这个方法也是对新段特定的搜集器 LeafCollector 的实现进行初始化的地方，Collector 的 `getLeafCollector()` 方法要返回针对于这个新段的 LeafCollector 实现。例如，可以利用 DocValues API。来检索方法提供的 LeafReaderContext 对应的值。

&emsp;&emsp;注意，相关性评分并不传递给 LeafCollector 的 `collect(int doc)` 方法。这为不需要评分的收集器节约了对 CPU 的浪费。取而代之的是，Lucene 在每个段的搜集器上，调用 LeafCollector 的 `setScorer(Scorer scorer)` 方法，来提供 Scorer 实例。LeafCollector 的实现应该保存这个实例，如果需要，则通过调用 `Scorer.score()` 方法，来得到当前匹配文档的相关性评分。这个方法必须在 `collect(int doc)` 方法的内部调用，因为它持有特定于当前收集 docID 的易变数据。注意，Scorer.score() 方法每次都会重新计算，因此，如果 `collect(int doc)` 方法中，多次调用 `Scorer.score()` 方法，应该在内部只调用它一次，然后简单的复用它返回的结果。另一种方案是，Lucene 提供的 **ScoreCachingWrappingScorer** 类， 是一个 缓存每个文档评分的 Scorer 实现。注意，Scorer 是一个复杂而高级的 API，但在这个上下文环境，只使用它的 score() 方法。


<br/><br/>
<a id="2"></a>

## 6.2.2 自定义收集器: BookLinkCollector ##

下面的 BookLinkCollector 类同时实现 Collector 和 LeafCollector 接口，构造匹配查询文档的唯一 URL 和对应的书名。如代码清单 6.2.2 所示：

<table width="100%"><tr><td bgcolor=green><font color=black>Listing 6.2.2 自定义 Collector 和 LeafCollector 实现：搜集匹配查询结果的链接和书名</td></tr></table>

```java
public class BookLinkCollector implements Collector, LeafCollector {
  private int docBase;
  private Scorable scorer;

  private Map<String,String> documents = new HashMap<String,String>();
  private BinaryDocValues urls;
  private SortedDocValues titles;

  public BookLinkCollector(){}


  @Override
  public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {
    doSetNextReader(context);

    return this;
  }

  /**
   * This method is called before collecting <code>context</code>.
   */
  protected void doSetNextReader(LeafReaderContext context) throws IOException {
    this.docBase = context.docBase;
    LeafReader reader = context.reader();

    urls = DocValues.getBinary(reader, "url");            // ①
    titles =  DocValues.getSorted(reader, "title2");      // ①
  }

  @Override
  public ScoreMode scoreMode() {
    return ScoreMode.COMPLETE_NO_SCORES;
  }

  @Override
  public void setScorer(Scorable scorer) throws IOException {
    this.scorer = scorer;
  }

  public void collect(int docID) throws IOException {
    String url = "";
    String title = "";
    try {
      if(urls.advanceExact(docID)) {
        url = urls.binaryValue().utf8ToString();
      }
      if(titles.advanceExact(docID)) {
        title = titles.binaryValue().utf8ToString();
      }

    }catch (IOException e){
      // ignore
    }
    documents.put(url, title);                          // ②
    System.out.println(title + ":" + scorer.score());
  }

  public Map<String,String> getLinks() {
    return Collections.unmodifiableMap(documents);
  }
}
```

① 载入 DocValues
② 将匹配的 ur, title 存入 map

BookLinkCollector 收集器与 Lucene 的正规搜索结果收集不同，它没有保留匹配文档的 docID。而是对每一个匹配的文档，将一对 URL 到 title 的映射添加到一个私有的 HashMap 中，然后在搜索完成后，使整个 Map 可以从外部访问。urls 和 titles 都是从索引段的 DocValues 取回的，`collect(int docID)` 方法的 docID 是段内文档 ID，因此可以直接通过这个 docID 获取段内 DocValues 的单个值。

使用自定义的 Collector 要求使用 IndexSearcher 的底层 search() 方法：

- **search(Query query, Collector results)** 

测试代码如代码清单 6.2.2-2 所示：

<table width="100%"><tr><td bgcolor=green><font color=black>Listing 6.2.2-2 测试自定义的 BookLinkCollector 类</td></tr></table>

```java
public class CollectorTest {

  @Test
  public void testCollecting() throws Exception {
    Directory directory = TestUtil.getBookIndexDirectory();
    TermQuery query = new TermQuery(new Term("contents", "junit"));
    DirectoryReader reader = DirectoryReader.open(directory);
    IndexSearcher searcher = new IndexSearcher(reader);

    BookLinkCollector collector = new BookLinkCollector();
    searcher.search(query, collector);

    Map<String,String> linkMap = collector.getLinks();
    assertEquals("ant in action",
                 linkMap.get("http://www.manning.com/loughran"));

    TopDocs hits = searcher.search(query, 10);
    System.out.println("---------------------------");
    TestUtil.dumpHits(searcher, hits);

    reader.close();
    directory.close();
  }
}
```

在搜索期间，Lucene 向我们的收集器传送每一匹配的文档的 docID，搜索结束后，确认由 BookLinkCollector 收集到的链接 map 中包含 "ant in action" 的正确链接 "http://www.manning.com/loughran"。

<br/><br/>
<a id="3"></a>

## 6.2.3 AllDocCollector ##

有时候，想要为搜索简单地记录每个匹配文档，并且知道匹配的数量不是很多。代码清单 6.2.3 展示了这样一个 Collector 实现，AllDocCollector 类。

代码位于本书代码 common 子模块。

<table width="100%"><tr><td bgcolor=green><font color=black>Listing 6.2.3 收集所有匹配文档和评分的收集器 AllDocCollector</td></tr></table>

```java

/**
 * Gathers all documents from a search.
 */

public class AllDocCollector implements Collector, LeafCollector {
  List<ScoreDoc> docs = new ArrayList<>();
  private Scorable scorer;
  private int docBase;

  @Override
  public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {
    this.docBase = context.docBase;
    return this;
  }

  @Override
  public ScoreMode scoreMode() {
    return ScoreMode.COMPLETE;
  }

  @Override
  public void setScorer(Scorable scorer) throws IOException {
    this.scorer = scorer;
  }

  public void collect(int doc) throws IOException {
    docs.add(
      new ScoreDoc(doc + docBase,       // ①
                   scorer.score()));        // ②
  }

  public void reset() {
    docs.clear();
  }

  public List<ScoreDoc> getHits() {
    return docs;
  }
}

```

① 变基为全局（绝对）docID
② 记录评分值

使用 AllDocCollector 收集搜索结果很简单：创建实例，把实例作为参数传给 `IndexSearcher.search(Query query, Collector results)`方法。搜索结束之后，调用 AllDocCollector 的 `getHits()` 方法检索所有的命中文档。


