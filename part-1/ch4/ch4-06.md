## 4.6 词干还原分析 Stemming analysis ##

最后一个要介绍的分析器用于移除全部停用词（stop word）。它具有一个描述性的名字：PositionalPorterStopAnalyzer。这个分析器移除停用词，在移除的停用词位置保留空位，并使用一个词干还原过滤器。

&emsp;&emsp;PorterStemFilter 展示在图 4.5 中的类继承结构中，但它没有用于内置分析器。它使用由 Martin Porter 博士创建的 Porter 词干还原算法还原单词词干。Porter 博士为该算法给出了最好的定义：

>**Porter 词干还原算法**（或称为 **Porter stemmer**）是对英文单词中较常见的，因时态、语态、复数格式等原因引起的词缀变化进行移除的过程。它主要用于信息检索系统的词项规范化处理。

换句话说，将某单词的各种变体形式还原为其通用词根的形式。例如，单词 breathe, breathes, breathing, breathed 通过 Porter 词干还原算法，还原为它们的原型词干 breath。

&emsp;&emsp;Porter 词干还原算法是众多词干还原算法之一。8.2.1 节通过 Lucene 扩展实现了 Snowball 词干还原算法（也是 Martin Porter 博士创建的）。KStem 是另一个词干还原算法，Lucene 也提供对该算法的支持。analyzers-common 模块提供了 org.apache.lucene.analysis.en.KStemmer 类和 org.apache.lucene.analysis.en.KStemFilter 过滤器，可供分析器使用。

<br/><br/>
<a id="1"></a>
## 4.6.1 StopFilter 保留空位 StopFilter leaves holes ##

停用词移除引出一个有趣的话题：由单词移除留下的空位会发生什么？假设对 "one is not enough" 进行索引，由 StopAnalyzer 分析输出的词元应该是 one 和 enough，is 和 not 会被丢弃。StopAnalyzer 通过递增位置增量来计数被移除的单词。从 AnalyzerUtils.displayTokensWithPositions() 方法的输出结果展示了这种情况:

```
2: [quick]
3: [brown] 
4: [fox] 
5: [jumps]
6: [over]
8: [lazy]
9: [dog]
```

位置 1 和 7 因为移除了单词 the 而消失了。

退一步将，移除停用词是英文这些单词通常没有什么特殊含义，它们是在各类语言中的 “粘合（glue）” 词。问题在于，由于将它们移除了，那么会导致丢失一些信息，那么这可能会也可能不会成为我们应用程序的一个问题。例如，上述例子的数据，非准确搜索也能匹配到 "a quick brown fox" 的文档。

&emsp;&emsp;还有一个有趣的替代方案，称为鹅卵石（shingles），它由多个邻近的词元混合而成。Lucene 的 analyzers-common 模块提供了 org.apache.lucene.analysis.shingle.ShingleFilter 过滤器，用于在分析时创建 shingles。详细内容参考 8.2.3 节。使用 shingles，停用词与邻近的词元组成新的词元，例如 'the-quick'。在搜索时，使用相同的扩充。这会使我们能够进行精确的短语匹配，因为停用词没有被移除。使用 shingles 可以产生很好的搜索性能，因为包含 'the-quick' 的文档比包含停用词 'the' 的文档要少得多。

<br/><br/>
<a id="2"></a>
## 4.6.2联合使用词干还原和停用词移除 Combining stemming and stop-word removal ##

这个自定义分析器使用停用词移除过滤器，保留停用词移除后的空位。经停用词过滤后的结果，经由 Porter 词干还原过滤器 PorterStemFilter 处理。代码清单 4.6 展示了这个复杂的分析器完整实现。

代码位于本书代码 analysis 子模块 net.mvnindex.demo.lucene.analysis.positional 包。

<table width="100%"><tr><td bgcolor=green><font color=black>Listing 4.6 PositionalPorterStopAnalyzer 分析器: 停用词移除和词干还原</td></tr></table>

```
public class PositionalPorterStopAnalyzer extends StopwordAnalyzerBase {
  private CharArraySet stopWords;

  public PositionalPorterStopAnalyzer() {
    super(EnglishAnalyzer.ENGLISH_STOP_WORDS_SET);
  }

  public PositionalPorterStopAnalyzer(CharArraySet stopWords) {
    super(stopWords);
  }

  @Override
  protected TokenStreamComponents createComponents(String fieldName) {
    LetterTokenizer source = new LetterTokenizer();
    TokenStream tokenStream = new LowerCaseFilter(source);
    tokenStream = new StopFilter(tokenStream, stopWords);
    tokenStream = new PorterStemFilter(tokenStream);

    return new TokenStreamComponents(
            r -> {source.setReader(r);},
            tokenStream);
  }
}

```

代码从 LetterTokenizer 分词器开始，经 LowerCaseFilter 过滤器后，转入 StopFilter 过滤器移除停用词，然后将移除停用词的词元流交由 PorterStemFilter 词干还原过滤器处理。分析器的最终处理结果就是 PorterStemFilter 过滤后的结果词元流。












