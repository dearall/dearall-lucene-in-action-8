## 2.3 基本索引操作 Basic index operations ##

&emsp;&emsp;前面我们讨论了 Lucene 有关文档建模的概念性方法，随后阐述了索引过程的逻辑步骤。现在是时候看一些实际代码，使用 Lucene API 来向索引中添加、删除、以及更新文档了。

<br/><br/>
<a id="1"></a>
## 2.3.1 IndexWriter 概述 Introduction of IndexWriter ##

&emsp;&emsp;**IndexWriter** 类是 Lucene 索引操作的顶级 API，位于 Lucene 核心模块的 org.apache.lucene.index 包中，用于创建和维护索引（JavaDoc: An IndexWriter creates and maintains an index），Lucene 所有关于索引的复杂结构和算法都隐藏在这个顶级类之下，它是所有索引操作的中心。

目前，IndexWriter 只有一个构造器：
- **IndexWriter(Directory d, IndexWriterConfig conf)**

其中 Directory 表示索引目录，IndexWriterConfig 表示 IndexWriter 的实例的配置选项。

&emsp;&emsp;**Directory** 是 Lucene 为存储索引文件提供的一个抽象层（JavaDoc: A Directory provides an abstraction layer for storing a list of files）。这个目录只包含文件（没有子目录结构）。它是一个抽象类，Lucene 为其提供了多种种类型的子类，例如 FSDirectory, RAMDirectory, FilterDirectory CompoundDirectory, FileSwitchDirectory 等等，以适应不同的存储环境。其中 RAMDirectory 表示内存中的 Directory 实现，它是测试代码的最佳选择。但由于其低效的同步问题从 Lucene 7.5 版本开始不再鼓励使用，且被 @Deprecated 标注，鼓励由 MMapDirectory 取代。虽然直到 8.12 版本还一直存在，但到 Lucene 9.0 版，RAMDirectory 已被移除。

&emsp;&emsp;**FSDirectory** 是基于 OS 文件系统 Directory 的抽象基类，Lucene 为其提供了三个核心子类：SimpleFSDirectory，NIOFSDirectory 和 MMapDirectory 这三个具体实现类，每一种实现在不同的操作系统上都有其优缺点，因此 FSDirectory 提供了**FSDirectory.open(Path path)** 和 **FSDirectory.open(Path path, LockFactory lockFactory)** 静态方法，由 Lucene 根据系统环境为我们选择最合适的具体子类实现，它们返回这三个子类之一的实例来为我们所用。

&emsp;&emsp;由于索引结构的复杂性，旧版本的 Lucene 通过多个重载构造器来构造 IndexWriter 对象，以提供多种初始化参数配置。随着 Lucene 索引结构变得越来越复杂，可配置变得参数越来越多，从 Lucene 3.1 版开始引入 **IndexWriterConfig** 配置参数，使得 IndexWriter 只需要一个 IndexWriterConfig 类型参数的构造器，就可以构造多种初始化信息 IndexWriter 对象。到了 Lucene 8.11 版，IndexWriterConfig 类已演变成从 LiveIndexWriterConfig 类继承的，拥有众多可配置选项的实体类，它类似于一个 POJO 形式的 Java 类，并且为绝大多数可配置选项提供了 setter 方法，而且这些 setter 方法的返回值也是 IndexWriterConfig 类型，这使我们可以将多个设置选项的调用链接在一个语句中执行。IndexWriterConfig 类有2个构造器，其中无参数构造器使用默认的 StandardAnalyzer 分析器构造 IndexWriterConfig 对象；另一个构造器则接受一个 Analyzer 类型的分析器对象来构造 IndexWriterConfig 实例，这使得我们可以为其提供不同类型的分析器来配置 IndexWriter，让 IndexWriter 在创建索引时使用我们所提供的分析器进行文本分析。注意，这个配置是没有 setter 方法的，也就是说，分析器配置只能通过 IndexWriterConfig 的构造器一次性设定，一旦 IndexWriterConfig 对象构造完成，是不能中途改变分析器的，这样也就保证了 IndexWriter 分析文本信息的一致性。

&emsp;&emsp;**IndexWriterConfig** 中可配置的选项非常丰富，前一节中提到的使用复合文件的配置和段的合并策略配置就是通过该对象的 setUseCompoundFile(boolean useCompoundFile) 和 setMergePolicy(MergePolicy mergePolicy) 方法配置的。Lucene 为 IndexWriterConfig 对象的每个选项都设置了默认的配置，因此创建好 IndexWriterConfig 对象后，不用设置任何选项，就可以直接作为构造器参数，即使用默认配置创建 IndexWriter 对象。

&emsp;&emsp;索引是存储于文件的，更确切地说，Lucene 索引是一个包含索引文件的文件系统目录，其中没有子目录，只包含一些同一级别且数量不定的文件。由位于 org.apache.lucene.store 包中的 Directory 类表示。因此，创建 IndexWriter 对象时会和文件系统关联，也就存在对文件系统的打开模式问题。IndexWriterConfig 定义了 IndexWriterConfig.OpenMode 枚举选项，可通过 IndexWriterConfig.setOpenMode(OpenMode) 来确定是创建一个新的索引，还是打开一个已存在的索引。IndexWriterConfig.OpenMode 枚举有3个可用的值: APPEND, CREATE, CREATE_OR_APPEND 。注意，即使有 reader 在使用索引的情况下，也可以使用 IndexWriterConfig.OpenMode.CREATE 模式打开索引，旧的 reader 可以继续在它打开时间点的快照版本上进行搜索，而不会看到新创建的索引，直到这个 reader 重新打开。在使用 IndexWriterConfig.OpenMode.CREATE_OR_APPEND 选项配置的情况下，如果在提供给 IndexWriter 构造器的路径上不存在索引，IndexWriter 会创建新的索引，否则，它会打开已存在的索引。默认值为 CREATE_OR_APPEND。

&emsp;&emsp;不论在哪种情况下，IndexWriter 通过 addDocument() 方法向索引中添加文档，通过 deleteDocuments(Term...) 或者 deleteDocuments(Query...)方法从索引中删除文档，更新文档通过 updateDocument()方法进行（实际上是先删除旧的文档，然后添加整个文档）。当我们完成添加、删除、以及更新文档操作后，应该调用 IndexWriter 的 close() 方法。

&emsp;&emsp;IndexWriter 所有改变索引的的方法都会返回一个 long 类型的序列号（sequence number），这个数字表示每次执行改变索引的有效序号。commit() 方法也会返回一个序列号，表示本次提交中的最后操作，所有小于这个值的序列号代表的操作会包含在这次提交内，大于这个值的序列号所代表的操作则不会包含在本次提交内。也就是说明哪些对索引的改变操作会包含在本次提交点内，哪些不会包含在内。序列号是临时性的数据，不会以任何形式保存到索引中，仅仅在单独的 IndexWriter 实例内有效。

&emsp;&emsp;打开一个 IndexWriter 对象会在 Directoy 表示是目录内创建一个锁文件（默认锁文件名为 write.lock）。试图在同一个索引目录内打开另一个 IndexWriter 会导致发生 LockObtainFailedException 异常。

<br/><br/>
<a id="2"></a>
## 2.3.2 向索引添加文档 Adding documents to index ##

&emsp;&emsp;我们看看如何创建新的所有并向其添加文档。向索引中添加文档的方法有两个：
-  **IndexWriter.addDocument(Iterable<? extends IndexableField> doc)** 向索引中添加一个文档。
-  **IndexWriter.addDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs)** 一次性向索引中添加一批文档。
  
&emsp;&emsp;旧版本的 IndexWriter 使用 addDocument(Document doc) 向索引中添加文档，从 Lucene 4.0 版开始，IndexWriter 使用更抽象的接口类型 Iterable<? extends IndexableField> 作为添加文档的参数类型，而作为域(field)类型的 IndexableField 也是接口类型，这给域的类型增加了更多的灵活性。

&emsp;&emsp;位于 org.apache.lucene.document 包的 **Document** 类实现了 Iterable<IndexableField> 接口，是一个简单的对象，作为域的容器，其中包含一个或多个域(a set of fields)，用于表示一个完整的文档。但它的地位和作用非常重要，是 Lucene 索引和搜索操作的单元(JavaDoc: Documents are the unit of indexing and search)，所有索引数据的管理和搜索结果的获取都通过 Document 对象进行，它是与索引交互的桥梁，类似于数据库中记录（Record）的概念。要说明的是，域(field)是真正携带数据内容的实体，它拥有一个名字和一个值，类似于数据库中列（Column）的概念。域可以通过文档存储，也可以不存储，如果设置为存储，在搜索到该文档时，域值可以从文档中获取回来。因此，每个文档应包含一个或多个设置为存储的域来唯一识别出该文档。

&emsp;&emsp;Field 类实现了 IndexableField 接口，是域对象的具体实现，它是 Lucene 索引的基础组件和基本元素。Field 是 Document 的一部分（JavaDoc: A field is a section of a Document）。每个域由由三部分组成：名字、类型、值。值可以是文本数据（String, Reader 或预分析的 TokenStream 类型），二进制数据（byte[] 类型），或者数值数据(Number 类型)。Field 并不一定存入索引，它是索引数据的携带者和索引方式控制者，是否存入索引，是可选的。如果存入索引，那么它可以在搜索结果的命中文档中获取回来。Field 类带有一个由 IndexableFieldType 接口表示的域类型，用于控制该 Field 在写入索引时的控制信息。通过这些控制信息，Field 控制着数据在索引中的处理方式，包括是否将其自身存入索引的选项。这个 API 及其相关的组件的内容非常丰富，会在后面不同章节逐步展开。

&emsp;&emsp;程序清单 2.1 显示了创建新索引和添加两个小文档的必要步骤。本例中，文档内容包含在源代码中的字符串里，但真实世界的文档内容应该来自于一个外部的数据源。

<table width="100%"><tr><td bgcolor=green><font color=black>Listing 2.1 添加文档 Adding documents to an index</td></tr></table>

```
public class IndexingTest {
  protected String[] ids = {"1", "2"};
  protected String[] unindexed = {"Netherlands", "Italy"};
  protected String[] unstored = {"Amsterdam has lots of bridges",
                                 "Venice has lots of canals"};
  protected String[] text = {"Amsterdam", "Venice"};

  private final String indexPath = "indexes";
  private Directory directory;
  private IndexWriter indexWriter;

  static final FieldType idType = new FieldType();        //①
  static final FieldType countryType = new FieldType();
  static final FieldType contentsType = new FieldType();
  static final FieldType cityType = new FieldType();

  static {                                                //②
    idType.setOmitNorms(true);                          
    idType.setIndexOptions(IndexOptions.DOCS);
    idType.setStored(true);
    idType.setTokenized(false);
    idType.freeze();

    countryType.setStored(true);
    countryType.setIndexOptions(IndexOptions.NONE);
    countryType.freeze();

    contentsType.setTokenized(true);
    contentsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
    contentsType.setStored(false);
    contentsType.freeze();

    cityType.setStored(true);
    cityType.setTokenized(false);
    cityType.setIndexOptions(IndexOptions.DOCS);
    cityType.freeze();
  }

  @Before
  public void setUp() throws Exception {        // ③
    directory = FSDirectory.open(Paths.get(indexPath));
    IndexWriterConfig config = new IndexWriterConfig(new WhitespaceAnalyzer());
    config.setMergeScheduler(new SerialMergeScheduler()); // ④
    indexWriter = new IndexWriter(directory, config); //⑤

    for (int i = 0; i < ids.length; i++) {
      Document doc = new Document();                  //⑥

      doc.add(new Field("id", ids[i], idType));       //⑦
      doc.add(new Field("country", unindexed[i], countryType)); // ⑦
      doc.add(new Field("contents", unstored[i], contentsType)); //⑦
      doc.add(new Field("city", text[i], cityType)); //⑦

      indexWriter.addDocument(doc); //⑧
    }
    indexWriter.commit();   // ⑨
  }

  @After
  public void tearDown() throws IOException {   //⑩
    indexWriter.close();
    directory.close();
    deleteDir(new File(indexPath));
  }

  public static void deleteDir(File dir) {
    if (dir.isDirectory()) {
      String[] children = dir.list();
      for (int i = 0; i < children.length; i++) {
        new File(dir, children[i]).delete();
      }
    }
    dir.delete();
  }

  protected long getHitCount(String fieldName, String searchString) throws IOException { // ⑪
    DirectoryReader reader = DirectoryReader.open(directory);
    IndexSearcher searcher = new IndexSearcher(reader);

    Term t = new Term(fieldName, searchString);
    Query query = new TermQuery(t);
    long hitCount = TestUtil.hitCount(searcher, query);
    reader.close();

    return hitCount;
  }

  @Test
  public void testIndexWriter() throws IOException {  // ⑫
    assertEquals(ids.length, indexWriter.getDocStats().numDocs);
  }

  @Test
  public void testIndexReader() throws IOException {  // ⑬
    IndexReader reader = DirectoryReader.open(directory);
    assertEquals(ids.length, reader.maxDoc());
    assertEquals(ids.length, reader.numDocs());
    reader.close();
  }
}
```
① 每个 Field 对象需要一个 IndexableFieldType 类型参数，用于指定所创建 Field 对象的域类型。实际上它是一个接口类型，由 FieldType 提供具体实现。FieldType 是一个类似于 IndexWriterConfig 的配置对象，用于指定要创建 Field 对象的详细配置信息。FieldType 的可配置信息非常丰富，涉及到 Field 对象的方方面面，后续章节会逐渐展开其细节内容。

② 静态代码块中详细配置每种域类型的选项信息。
③ setup() 方法首先建立新的 Directory 对象用来存放索引目录。
④ 为了代码能同步反映出合并前后索引库的变化，这里使用 SerialMergeScheduler 配置合并调度器。默认的 ConcurrentMergeScheduler 合并调度器在一个后台线程上执行合并过程，会影响测试效果。
⑤ 在 Directory 对象上创建 IndexWriter 对象。
⑥ 创建 Document 对象，用于存放接下来的多个 Field 实例。
⑦ 将 4 个创建好的 Field 对象添加到 Document 对象。
⑧ 将 Document 对象添加到 IndexWriter 执行添加文档到索引库操作。
⑨ 将所有文档加入到索引之后，做一次提交操作，以使后面打开的 IndexReader 能完全看到索引库中这两个文档数据。
⑩ 资源清理，关闭 writer，directoy，并删除目录。
⑪ 虽然是一个工具方法，实际上它是建立了一个简单的 TermQuery 查询来搜索在 setup() 方法中建立好的索引库，并返回搜索结果的 hitCount 值，也就是匹配查询字符串的文档总数。
⑫ 验证写入的文档数和索引中存在的文档数相等。
⑬ 验证写入的文档数与 reader 读取索引所获得的文档数相等。其中 reader.maxDoc() 返回索引库当前提交点上所有的文档数量，包括被删除的文档。reader.numDocs() 返回索引库当前提交点上所有存活的的文档数量，不包括删除的文档。



<br/><br/>
<a id="3"></a>
## 2.3.3 删除索引中的文档 Deleting documents from an index ##

&emsp;&emsp;从索引中删除文档是维护索引工作中必不可少的操作。IndexWriter 为此提供了多种方法来从索引中删除文档。
- deleteAll() 删除索引中所有的文档。此方法会丢弃缓存中的全部文档，并删除索引中的所有段。索引的变化不会立刻可见，直到调用 commit() 方法。这个方法调用的结果可以通过执行 rollback() 方法回滚到原来的状态，条件是还没有调用 commit() 方法。
- deleteDocuments(Query... queries) 删除任何匹配查询条件的文档。查询条件可以提供一个或多个，由 Query 类型表示，索引中的文档只要匹配其中的一个就会被删除。在内部，这些匹配的文档的删除和刷新操作是原子性的，作为一个整体会在同一时刻执行。
- deleteDocuments(Term... terms) 删除任何包含给定 Term 的文档。提供的 Term 可以是一个或多个。在内部，所有复合条件文档的删除和刷新操作是原子性，作为一个整体会在同一时刻执行。
- tryDeleteDocument(IndexReader readerIn, int docID) 高级用法：试图通过 document ID 来删除文档，要求提供的 reader 是一个**近实时的(near-real-time, NRT)**。近实时搜索是 Lucene 2.9 版提供的一个高级特性，本章 2.8 节论述。通过 DirectoryReader.open(IndexWriter) 获取 NRT reader 对象，而且段还没有进行合并，那么删除会成功，并且方法返回一个有效的序列号（大于 0），否则删除操作会失败，返回值为-1，调用方必须另外通过上述两个删除方法通过 Term 或 Query 来删除。注意，该方法只能删除对于当前 NRT reader 可见的文档。如果需要删除打开 NRT reader 之后索引的文档，必须通过 deleteDocuments(Term...) 方法。

&emsp;&emsp;删除操作用到了搜索的概念和组件，这里的 Query 和 Term 都是搜索组件，目的是找出要删除的文档。这里我们不过多展开讨论，在第3章及后续章节会有详细阐述。为了说明删除操作，此处只简单介绍 Term 的概念。

&emsp;&emsp;Term 表示为一个文本的词，它是搜索的单元（JavaDoc: A Term represents a word from text. This is the unit of search）。它由两个元素组成：一个是词的文本，是一个字符串，另外一个是域的名字，表示这个词存在于这个名字表示的域（field）中。这是搜索单元与索引单元关联的基础信息，域名称（field name）。在 Lucene 中，Term 对象表示的单元我们称为词项（term）。注意，文本域中，term 可以表示为多个单词组成的词，类似于日期文本、email 地址、url 字符串等等。

&emsp;&emsp;如果需要通过 Term 删除单个文档，必须确保在每个文档中都通过 Field 对象索引了这个域（通过相同的域 name 标识），并且索引中所有 document 的这个域的域值唯一，这样才能将这个文档单独找出来将其删除。这与数据库中表的主键（primary key）具有相同的概念，但在 Lucene 中没有这种强制的方法。可以给这个域设置任何名字（通常用 ID 这个名字），这个域应该被设置为不经分析的索引（通过 FieldType.setTokenized(false) 来禁用对域值文本的分析），以确保其不会被分析器切分成分离的词元。然后利用该域来删除对应的文档，如下：

```
writer.deleteDocuments(new Term("ID", documentID));
```
&emsp;&emsp;调用该方法时一定要小心！如果偶尔指定了一个错误的 Term 对象（例如，使用了一个普通的被索引的文本域，而不是我们唯一值的 ID 域创建的 Term 对象），就可能轻易并快速地从索引中删除大量文档。不论是哪种情况，删除都不会立即执行，而是缓存在内存中，就像添加文档时一样，IndexWriter 会周期性将文档操作刷新到目录中。和添加文档一样，必须调用 IndexWriter.commit() 或 IndexWriter.close() 方法才能将改变提交到索引中。不过即使每次删除操作刷新到目录中，文档占用磁盘空间也不会立即释放。Lucene 只是将该文档标记为“删除（deleted）”，2.13.2节会阐述该过程的具体细节。

我们看看程序 2.2 中 deleteDocuments() 方法的实践。代码展示了 deleteDocuments() 方法的使用，并演示了对索引中文档数量进行统计方法的使用。

<table width="100%"><tr><td bgcolor=green><font color=black>Listing 2.2 从索引中删除文档 Deleting documents from an index</td></tr></table>

```
  @Test
  public void testDeleteBeforeFlush() throws IOException {
    assertEquals(2, indexWriter.getDocStats().numDocs);   //①

    indexWriter.deleteDocuments(new Term("id", "1"));     //②
    assertTrue(indexWriter.hasDeletions());               //③

    assertEquals(2, indexWriter.getDocStats().maxDoc);    //④
    assertEquals(2, indexWriter.getDocStats().numDocs);   //⑤

    DirectoryReader reader = DirectoryReader.open(directory);     //⑥
    System.out.println("total docs: " + reader.maxDoc());
    System.out.println("live docs: " + reader.numDocs());
    System.out.println("deleted docs: " + reader.numDeletedDocs());
    reader.close();

    System.out.println("--------------");

    reader = DirectoryReader.open(indexWriter);                   //⑦
    System.out.println("total docs: " + reader.maxDoc());
    System.out.println("live docs: " + reader.numDocs());
    System.out.println("deleted docs: " + reader.numDeletedDocs());
    reader.close();
  }

```
① 确认当前索引中有2个文档
② 删除 id 值为 1 的文档
③ 确认 writer 中有删除的文档
④⑤ 索引中文档数量没有发生变化。我们只做了一个删除文档操作，此时不会触发 indexWriter 的缓存刷新，也不会触发合并操作的执行。indexWriter 看到的索引库的文档状态与删除操作之前一样，它不会包含缓存中的操作，因此，当前状态下索引库中文档总数仍然是最开始的 2，存活的文档数量也是 2，它不会考虑缓存中删除的文档。
⑥ 删除文档后，通过 DirectoryReader.open(directory) 打开索引库最后提交点上的 IndexReader 对象，并输出 3 个索引库文档统计数据，其中 reader.numDeletedDocs() 输出的是已删除文档数量。输出结果如下：
```
total docs: 2
live docs: 2
deleted docs: 0
```
可以看到，文档总数和存活数都是 2，被删除的文档数为 0，表明 DirectoryReader.open(directory) 打开的 IndexReader 是索引库最新提交点上的数据，并不包含 indexWriter 最新的删除信息。 
⑦ 通过 DirectoryReader.open(indexWriter) 再次打开一个 IndexReader 实例，这次是已近实时（near real time）的方式打开，输出结果如下：
```
--------------
total docs: 2
live docs: 1
deleted docs: 1
```
文档总数依然是2，这次存活的文档数变为 1，删除的文档数变为 1，表明以近实时方式打开的 reader 能看到 writer 缓存中的变化，即便 writer 还没有刷新或提交到索引库中。


再看一个 deleteDocuments() 方法的代码实践。代码展示调用 deleteDocuments() 方法对索引库做出改变之后，主动刷新缓存前后索引库的变化。

<table width="100%"><tr><td bgcolor=green><font color=black>Listing 2.2-1 从索引中删除文档并刷新缓存 Deleting documents from an index and flush cache</td></tr></table>

```
  @Test
  public void testDeleteAfterFlush() throws IOException {
    assertEquals(2, indexWriter.getDocStats().numDocs); //①

    indexWriter.deleteDocuments(new Term("id", "1"));   //②
    indexWriter.flush();                                //③
    assertFalse(indexWriter.hasDeletions());            //④

    assertEquals(1, indexWriter.getDocStats().maxDoc);  //⑤
    assertEquals(1, indexWriter.getDocStats().numDocs); //⑥

    DirectoryReader reader = DirectoryReader.open(directory);   //⑦
    System.out.println("total docs: " + reader.maxDoc());
    System.out.println("live docs: " + reader.numDocs());
    System.out.println("deleted docs: " + reader.numDeletedDocs());
    reader.close();

    System.out.println("--------------");

    reader = DirectoryReader.open(indexWriter);                  //⑧
    System.out.println("total docs: " + reader.maxDoc());
    System.out.println("live docs: " + reader.numDocs());
    System.out.println("deleted docs: " + reader.numDeletedDocs());
    reader.close();
  }
```
① 确认当前索引中有2个文档
② 删除 id 值为 1 的文档
③ 调用 indexWriter.flush() 刷新 writer 缓存，此时会在索引库中创建新的段
④ 确认刷新后，writer 中已没有了删除操作，因为刷新操作会将缓存的内容写入到新创建的索引段中
⑤⑥ 确认 indexWriter 看到的文档数量为 1，因为删除了一个
⑦ 通过 DirectoryReader.open(directory) 打开索引库最后提交点上的 IndexReader 对象，并输出 3 个索引库文档统计数据，其中 reader.numDeletedDocs() 输出的是已删除文档数量。输出结果如下：
```
total docs: 2
live docs: 2
deleted docs: 0
```
文档总数和存活数都是 2，被删除的文档数为 0，表明 DirectoryReader.open(directory) 打开的 IndexReader 是索引库最新提交点上的数据，并不包含 indexWriter 最新的删除信息。

⑧ 通过 DirectoryReader.open(indexWriter) 再次打开一个 IndexReader 实例，这次是已近实时（near real time）的方式打开，输出结果如下：
```
--------------
total docs: 1
live docs: 1
deleted docs: 0
```
文档总数变为 1，存活的文档数变为 1，删除的文档数变为 0，表明以近实时方式打开的 reader 能看到 writer 缓存和新索引段的变化，即便 writer 还没有提交到索引库中。




<br/><br/>
<a id="4"></a>
## 2.3.4 更新索引中的文档 Updating documents in the index ##

&emsp;&emsp;更新索引是索引维护过程中的重要操作。很多搜索程序在首次索引完文档后，可能需要对文档进行后续的深度修改，这要求重新索引文档。例如，文档是从某个 web 服务器上爬取回来的，一种检查内容发生变化的方法是查看 ETag HTTP 头是否发生改变。如果它与上次索引该文档时不同，就意味着文档内容发生了变化，我们应更新索引中的这个文档。

&emsp;&emsp;在某些情况下，我们可能只想更新文档中几个特定的的域，比如标题变了，而正文没有变。对于这类情况，Lucene 也为我们提供了相应的方法来更新文档。

&emsp;&emsp;IndexWriter 提供了多个文档更新的方法：
- **updateDocument(Term term, Iterable<? extends IndexableField> doc)** 基本用法：通过先删除含有指定 term 的文档，然后再向索引添加新文档的方法更新文档。删除和添加组成一个原子操作。
- **updateDocuments(Term delTerm, Iterable<? extends Iterable<? extends IndexableField>> docs)** 基本用法：删除匹配指定 delTerm 的文档，然后向索引添加一批文档。该操作是原子性的。
- **updateDocValues(Term term, Field... updates)** 用给定的值更新匹配文档的 DocValues 域，所有更新操作的执行和刷新都是原子性的。如果给定的 doc values 域的数据为 null, 那么当前存在的值将从所有匹配文档中移除。
- **updateNumericDocValue(Term term, String field, long value)** 用给定的值更新文档的 NumericDocValues 类型的域。只能用该方法更新索引中已存在的域，不能通过该方法添加新的域。
- **updateBinaryDocValue(Term term, String field, BytesRef value)** 用给定的值更新文档的 BinaryDocValues 类型的域。只能用该方法更新索引中已存在的域，不能通过该方法添加新的域。
- **tryUpdateDocValue(IndexReader readerIn, int docID, Field... fields)** 高级用法：试图通过 document ID 来更新文档，要求提供的 reader 是一个**近实时的(near-real-time, NRT)**。近实时搜索是 Lucene 2.9 版提供的一个高级特性，本章 2.8 节论述。通过 DirectoryReader.open(IndexWriter) 获取 NRT reader 对象，而且段还没有进行合并，那么更新操作会成功，方法返回一个有效的序列号（大于 0），否则更新操作会失败，返回值为-1，调用方必须重试更新操作。如果给定的 doc values 域的数据为 null, 那么当前存在的值将从所有匹配文档中移除。注意，该方法只能更新对于当前 NRT reader 可见的文档。如果需要更新打开 NRT reader 之后索引的文档，必须通过 updateDocValues(Term, Field...updates) 方法。
- **softUpdateDocument(Term term, Iterable<? extends IndexableField> doc, Field... softDeletes)** 高级用法：首先用给定的 doc-values 域更新所有具有给定 term 的文档，然后向索引中添加新的文档。doc-values 更新和随后的添加操作是原子性的。
- **softUpdateDocuments(Term term, Iterable<? extends Iterable<? extends IndexableField>> docs, Field... softDeletes)** 高级用法：首先用给定的 doc-values 域更新所有具有给定 term 的文档，然后向索引中添加新的一批文档。doc-values 更新和随后的添加操作是原子性的。

&emsp;&emsp;前两个标为*基本用法*的方法是更新操作的常规用法，之后列出的方法是随着 Lucene 版本更新加入的新方法，属于高级应用，以解决不同场景的更新需求。基本的更新操作如下所示：

```
writer.updateDocument(new Term("ID", documenteId), newDocument);
```

&emsp;&emsp;由于 updateDocument() 方法在底层使用 deleteDocuments() 方法，因此给出同样的提示：要确保被更新文档 Term 的唯一性。程序清单 2.3 为更新文档示例：

<table width="100%"><tr><td bgcolor=green><font color=black>Listing 2.3 更新索引中文档 Updating indexed Documents</td></tr></table>

```
  @Test
  public void testUpdate() throws IOException {
    assertEquals(1, getHitCount("city", "Amsterdam"));

    Document doc = new Document(); // ①
    doc.add(new Field("id", "1", idType));
    doc.add(new Field("country", "Netherlands", countryType));
    doc.add(new Field("contents", "Den Haag has a lot of museums", contentsType));
    doc.add(new Field("city", "Den Haag", cityType));

    indexWriter.updateDocument(new Term("id", "1"), doc); // ②

    indexWriter.commit(); //③

    assertEquals(0, getHitCount("city", "Amsterdam")); //④
    assertEquals(1, getHitCount("city", "Den Haag"));  //⑤
  }
```

① 创建新文档
② 用新文档更新索引
③ 为了在之后的搜索中反映出索引库更新后的数据，此处进行一次强制提交
③ 确认旧文档已不在索引库中
④ 确认新文档存在于索引库中

本例，通过 updateDocument() 方法，用新文档替换 id 为 1 的旧文档。这样，就实现了对索引中文档的更新操作。
