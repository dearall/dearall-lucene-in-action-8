## 2.0 关于索引的基本概念及 API 简介##

&emsp;&emsp;在进入索引的详细讨论之前，有必要先对 Lucene 中涉及的信息检索方面相关的技术概念做简要的介绍。并且，Lucene 提供的有关索引部分核心 API 的内容，随着版本的迭代，也变得越来越丰富，在进入每个 API 的细节探讨之前，也有必要在更高层次上进行必要的梳理，以形成整体的功能和特性逻辑。

&emsp;&emsp;实际上 Lucene 所用的信息检索方面的术语基本与 Information Retrieval（《信息检索》原版）保持一致。比如 Term、Dictionary、Postings、Index 等。

<br/><br/>
##### <font size=3 color=green>索引（Index）</font> #####
对于初学全文检索的人来说，索引这个词非常具有迷惑性，主要原因是，不论是中文还是英文，它都具有两个词性：
- **动词**：做动词时，一般英文写为 “indexing”，比如 “索引一个文件” 翻译为 “indexing a file”，它是指我们将原始数据经过一系列的处理，最终形成可以高效全文检索的过程，对于 Lucene 来说，就是生成倒排索引的过程。这个过程称之为索引（indexing）。本书为了方便和表达准确，有时使用中文 “建立索引” 来表示 英文动词的 indexing 语义。
- **名词**：做名词时，写为 “index”。经过 indexing 最终形成的数据集合称之为索引（index）。本书为了方便和表达准确，有时使用中文 “索引库” 来表示英文名词的 index 语义。

所以，见到索引（index）这个词，一定要分清楚是动词还是名词。后面为了清楚，凡是作为动词的时候我使用 indexing，作为名词的时候使用 index。Index 是 Lucene 中的顶级逻辑结构，它是一个逻辑概念，表示可搜索的数据集合。如果对应到具体的实物，就是一个目录，目录里面所有的文件组成一个 index。注意，这个目录里面不会再嵌套目录，只会包含多个文件。对应到代码里面，就是 org.apache.lucene.store.Directory 这个抽象类。

最后要说明一点的是，Lucene 中 index 和 ElasticSearch 中的 index 不是一个概念，ElasticSearch 中的 shard 对应的才是 Lucene 的 index 概念。

<br/><br/>
##### <font size=3 color=green>文档（Document）和域（Field）</font> #####

&emsp;&emsp;一个索引库中会包含若干个文档，英文是 **Document**，类似于关系型数据库中的一条记录（record），在 Lucene 中，**文档** 是索引和搜索操作的原子单位，表示的也是一条完整的记录。Document 与通常意义的文件具有不同概念和语义。

&emsp;&emsp;文档是一个灵活的概念，不同的业务场景对应的具体含义不同。对于搜索引擎来说，一个文档可能就代表爬虫爬到的一个网页，很多个网页（文档）组成了一个索引。而对于提供检索功能的邮件客户端来说，一个文档可能就代表一封邮件，很多封邮件（文档）组成了一个索引。再比如假设我们要构建一个带全文检索功能的商品管理系统，那一件商品就是一个文档，很多个商品组成了一个索引。对于日志处理，一般是一行日志代表一个文档。

&emsp;&emsp;**Field** 这个英文单词，在中文语境中有多种不同的翻译，Java 语言里把它译为“字段”，C/C++ 中把它译为“字段”或者“域”，都行。关系型数据库描述中有一般使用另一个具有相同语义的单词 column，译为“列”。Lucene 中的 Field 与 Java/C/C++ 中的 field，以及数据库中的 column 具有相同的语义，表示携带或者持有数据的实体单元。国内有的将其译为“字段”，也有的译为“域”，都能表达其语义。本书为了表述的一致性，将其译为“**域**”，这个词似乎更能表达 Lucene 中数据携带者的抽象性。

&emsp;&emsp;文档中包含若干个域，域是真正的数据携带者，数据要从外部进入索引，首先要存储到域中，然后才能把它加入索引库。Lucene 提供了 Field 及其丰富的子类来表示域的概念，方便我们应对各种类型的数据。

&emsp;&emsp;不同于传统的关系型数据库，Lucene 不要求一个索引库中所有文档的域保持一致，如果愿意，每一个文档的结构都可以不同（当然并不推荐这样做），而且不需要事先定义，这个特性一般称为 “flexible schema”。传统的关系型数据库要求一个表中的所有记录的结构必须一致，而且必须事先定义好，称为 “strict schema” 或者 “fixed schema”。比如，一个名为 “mixture” 的索引包含3个文档，如下所示：

```
{
    { "name": "Ni Yanchun", "gender": "male", "age": 28  },
    { "name": "Donald John Trump", "gender": "male", "birthday": "1946.06.14"},
    { "isbn": "978-1-933988-17-7", "price": 60, "publish": "2010", "topic": ["lucene", "search"]}
}
```

可以看到，3 个文档的字段并不完全一样，这在 Lucene 中是合法的。


<br/><br/>
##### <font size=3 color=green>词元（Token）和词项（Term）</font> #####

&emsp;&emsp;词元（Token）和词项（Term）是 Lucene 中两个最小的索引单元术语，从用户级 API 的角度来看，它们都是原子性的，没有比它们更细粒度的元素了。

&emsp;&emsp;英文单词 **Token** 意为“标志”、“记号”之类的符号性元素，在信息分析领域意为“词及其的元数据”，翻译为 “词单元”、“词项单元”、或者 “词元”，本书统一使用 “**词元**” 这个词作为 Token 的中文术语。

&emsp;&emsp;英文单词 **Term** 意为“术语”，在 Lucene 中，Term 是与词相关的含义，它由一个域名称（field name）和一个词组成，是一个与索引和搜索相关的关于词的概念，本书将其译为 “**词项**”。与之关联的还有一个术语 **Term Vector**，我们将其译为 “**词向量**”。

&emsp;&emsp;词元 Token 是存储在字段中的文本数据经过分词器（Tokenizer）分词后产生的一系列词或者词组，以及这些词或词组本身在原始文本中的一些属性信息，例如可选的词频 TF、位置 postion、字符偏移量 offset、附加数据 payload 等信息，为了表述方便，我们把这些属性统称为 token 的元数据。举例来说，假设有个 "body" 字段的存储的值为 "the quick brown fox jumped over the lazy dog"，这个字段经过 Lucene 的标准分词器分词后的结果是："the" "quick" "brown" "fox" "jumped" "over" "the" "lazy" "dog"。这里的每个词就是一个 token，当然除了词自身外，token 还会包含上述的元数据信息。

&emsp;&emsp;一个 token 加上它所属的域的名称构成了一个 Term。比如 "body" 和 "quick" 组成一个 Term，"body" 和 "fox" 组成另外一个 Term。我们检索的时候搜的就是 Term，而不是 Token 或者 Document。搜索 Term 时，会找到包含这个 Term 的文档的 ID 号码，即 docId，然后通过 docId 返回整个 Document。注意，Term 通过域的名字和域关联，即 Term 含有域信息，具有不同名字但有相同内容的 Term 是不同的，例如 "title":"fox" 和 "body":"fox" 是不同的 Term。



<br/><br/>
##### <font size=3 color=green>索引段 Segment</font> #####

&emsp;&emsp;**Segment** 这个英文单词意为 “部分”、“分段”，这个含义应用到 Lucene 的索引中，意为 “索引库的分段”。我们在术语中将其译为 “**段**” 或 “**索引段**”，这两个词都会在书中使用。

&emsp;&emsp;Lucene 在建立索引的时候，并不是将所有数据写到一起，而是将索引数据写入段中。搜索时，实际上是在索引库的段上进行搜索。如果索引库有多个段，而且大多数情况下就是如此，那么就会在多个索引段上进行搜索，Lucene 将每个段上的搜索结果汇总起来作为最终的搜索结果返回给搜索调用者。索引的时候，会先将 Document 缓存，然后定期将缓存刷新到文件。每次刷新就会生成一个索引段。因此一个索引库中包含若干个索引段是很正常的。每个索引段是一个具有完整数据的小型索引库，所有的索引段组成了整个索引。为了减少文件描述符的使用，索引库中那些小的索引段会定期的合并为（merge）大的索引段，然后将这些小索引段从索引库中删除。数据量不大的时候，合并之后一个索引库可能只有一个索引段。



<br/><br/>
<a id="1"></a>
## 2.0.1 索引 API 概述（Index APIs） ##

<br/>
#####<font size=3 color=green>IndexWriter</font> #####

&emsp;&emsp;IndexWriter 是一个具体的类，位于 Lucene 的 org.apache.lucene.index 核心包。它用于创建索引库，向索引中库添加文档、更新或删除索引库中已存的文档。IndexWriter 类是线程安全的，并且强制每个索引库只能有一个 IndexWriter 实例。创建 IndexWriter 的一个实例是创建一个新的索引库，或者打开一个已存在的索引库，索引库的位置信息由提供给 IndexWriter 构造器的 Directory 类型实例定义，而丰富的配置选项信息则由 IndexWriter 构造器的第二个参数 IndexWriterConfig 提供。一个Directory 是一个索引库存储位置信息的逻辑抽象，一般具体表现为一个本地文件系统目录，FSDirectory 是继承自 Directory 的表示这种本地文件系统目录的抽象基类，它有 3 个具体的子类：MMapDirectory、NIOFSDirectory 和 SimpleFSDirectory。但 Directory 也可以表示其它一些存储技术的索引库目录，比如内存上的文件系统目录。


<br/>
#####<font size=3 color=green>IndexReader</font> #####

&emsp;&emsp;IndexReader 也位于 Lucene 的 org.apache.lucene.index 核心包，用于从索引库中读取数据，并用于支持搜索操作。多个线程安全的 IndexReader 可以通过调用 DirectoryReader.open(org.apache.lucene.store.Directory) 方法并发打开，不管当前索引库上有没有打开的 IndexWriter 实例。每个 reader 维护索引库一个完整的时间点（point in time）视图，并且，该 reader 必须通过显式地刷新操作才能看到从它打开之后到现在最新写入的变化。可以通过调用 DirectoryReader.openIfChanged(org.apache.lucene.index.DirectoryReader) 方法获得最新索引视图。


<br/>
#####<font size=3 color=green>Segments and docids</font> #####

&emsp;&emsp;Lucene 的索引库是由索引段（segments）组成的，每个索引段包含索引库中所有文档的一个子集，而其本身通过这个文档子集，成为一个完整的可搜索的索引。当文档写入索引库时，会创建新的索引段并被刷新到目录中存储。索引段是不易变的，更新或删除操作只会创建新段，不会修改某个已存在的段。随着时间的推移，writer 会分将一些的小的段划分到组中，把它们合并为一个大的索引段来维护索引库，使其高效搜索，并释放那些已被标记为删除或更新的文档所占用的文件系统空间。

&emsp;&emsp;每个文档用一个32位数字标识，称为 "docid"。一个文档由各种类型 Field 值的集合组成，例如 倒排表（postings）、存储域（stored fields）、文档值（doc values）、point 表示的数值型数据（points）。

&emsp;&emsp;docid 有两种形态：全局性的和段内部的。一个文档的全局 docid 由每个段内部的 docid 与该段的基础 docid 偏移量（that segment's base docid offset）相加而得到。外部的高级 API 只使用全局性的 docid，而内部引用 LeafReader 类的 API 使用段内部 docid。LeafReader 是针对一个索引段的 reader，它是 IndexReader 的子类。

&emsp;&emsp;在每个索引段内部，docid 是按顺序分配的，从 0 开始，因此，每个段内文档的数量和它的最大 docid 值相同。这个最大值应该是给下一个要加入的文档预留的，还没有对应的文档。一旦新段创建完毕，这个值也不会再变了，因为段是不易变的，一经创建完毕，就不会被修改了。如果之后有文档被删除，也不会直接删除段内的文档，只是多删除文档做了删除标记，文档和它对的 docid 依然会保留其中，直到段被合并到其它新建的索引段中。当段被合并时，它所包含的文档会由新索引段分配新的顺序 docid。因此，docid 值只能作为内部实现使用，不能暴露为程序的一部分，也不能存储起来，也不能在 Lucene 的内部 API 之外引用。


<br/><br/>
<a id="2"></a>
## 2.0.2 域的类型 Field types ##

<br/>
#####<font size=3 color=green>倒排表（postings）</font> #####

&emsp;&emsp;Lucene 支持多种不同文档域数据结构。Lucene 的核心，倒排索引（the inverted index），由“倒排表（postings）”组成。倒排表，可以把它想象为一个 map，利用词项词典，对一个给定词项 Term（大致为一个单词或者词元）到包含该 Term 的所有文档（一个排序的 Document 列表），提供高效的查找功能。编码可以添加附加的记录来影响倒排表，使其在搜索时跳过那些低评分的文档。倒排表不提供任何形式的从一个给定的文档中检索词项的能力，除了扫描整个索引库。

<br/>
#####<font size=3 color=green>存储的域（stored field）</font> #####

&emsp;&emsp;存储的域（stored field）与倒排表完全相反，它为一个给定的 docid 提供域值的高效检索功能。一个文档的所有存储的域值都作为一个块存储在一起。建立在底层字节存储之上，不同类型存储的域提供了高级别数据类型，例如字符串和数值。通常 searcher 使用 StoredFieldVisitor 的实现来检索存储的域值。

<br/>
#####<font size=3 color=green>DocValues</font> #####

&emsp;&emsp;DocValues 域有时被称为列式存储器（columnar），或者 column-stride 域。对比关系型数据库术语，文档作为数据库中的行，而域作为数据库的列。DocValues 域是按域存储的：每个文档的某个值由一个单独的数据结构持有，对一个给定的 docid，提供域到值（field-value）的快速顺序查找。这种类型的域用于基于值（value-based sorting）的高效排序，以及 faceting，但它们对过滤没什么用。


<br/>
#####<font size=3 color=green>PointValues</font> #####

&emsp;&emsp;PointValues 通过 kd-tree 数据结构表示数字型值。可以实现一维到多维的数值类型数据，使得数值范围和区间查询，以及地理空间查询非常高效。





