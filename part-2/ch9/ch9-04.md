## 9.4 内置任务 Built-in tasks ##

讨论了属性设置和控制结构，联合使用这些功能可以将多个任务组合成更大的任务序列。现在，要对 benchmark 内置的任务进行深入地探讨。表 9.6 阐述内置的管理任务，表 9.7 阐述索引和搜索任务。

如果算法脚本中的命令不适合需要，可以向 org.apache.lucene.benchmark.byTask.tasks 包添加新任务来添加命令。应该从 PerfTask 抽象类扩展。确保新的任务类名以 Task 作为后缀。例如，一旦编译了 SliceBreadTask.java 类，并确保它被指定在 Ant 的类路径上，那么就可以在算法脚本文件中使用 SliceBread 来调用这个任务。

<br/>

<div>表 9.6 管理任务 Administration tasks</div>

<table width="100%">
    <tr bgcolor=#AA0000>
        <th align=center>任务名</th>
        <th align=center>说明</th>
    </tr>
    <tr>
      <td>ClearStats</td>
      <td>清除全部统计信息。报告任务运行到这一点之后，只包含运行在这个任务之后任务的统计信息。</td>
    </tr>
    <tr>
      <td>NewRound</td>
      <td>启动新一轮测试。这个命令在最外层序列的结束位置最有意义。这个任务会使一个 "round counter（轮次计数器）" 计数器递增。所有启动的任务都会记录这个新的轮次，并且它们的统计信息会被聚合在这个新的轮次下执行。例如 RepSumByNameRound 报告任务。另外，如果属性为每一轮指定了不同的设置，NewRound 会移动到下一个属性值。例如，属性被设置为 merge.factor=mrg:10:100:10:100，在每一轮之后，merge.factor 会使用下一个值。注意，如果轮次数比属性配置的数量更多，它就简单地从属性设置的开头再次轮回。</td>
    </tr>
    <tr>
      <td>ResetInputs</td>
      <td>重新初始化文档源和查询源回到起始状态。举例来说，一个很好做法是，把这个调用插入到 NewRound 之后，以确保每一轮的执行，文档源提供完全相同的文档。该任务仅在不想耗尽内容源时才有必要这样做。</td>
    </tr>
    <tr>
      <td>ResetSystemErase</td>
      <td>重置全部索引和输入数据，并调用 System.gc() 回收内存。这个任务不会重置统计信息。它也会调用 ResetInputs 任务。所有的 writer 和 reader 都关闭，用 null 对其赋值，以及删除。索引库及其目录被删除。如果是要向索引中添加文档，在调用这个任务之后，必须调用 CreateIndex 任务创建新的索引。</td>
    </tr>
    <tr>
      <td>ResetSystemSoft</td>
      <td>与 ResetSystemErase 任务类似，除了索引和工作目录不被删除。这个任务对测试打开现有索引进行搜索或更新性能很实用。可以在这个任务重置之后，使用 OpenIndex 任务。</td>
    </tr>
</table>



<br/><br/>
<div>表 9.7 内置索引和搜索任务 Built-in tasks for indexing and searching</div>

<table width="100%">
    <tr bgcolor=#AA0000>
        <th align=center>任务名</th>
        <th align=center>说明</th>
        <th align=center>参数</th>
    </tr>
    <tr>
      <td>CreateIndex</td>
      <td>利用 IndexWriter 创建一个新的索引库。之后可以使用 AddDoc 和 UpdateDoc 任务为索引库添加索引内容。</td>
      <td></td>
    </tr>
    <tr>
      <td>OpenIndex</td>
      <td>通过 IndexWriter 打开一个已存在的索引。之后可以使用 AddDoc 和 UpdateDoc 任务为索引库添加索引内容。</td>
      <td><b>commitName</b>：一个字符串标签，指定要打开哪个提交。这个参数值必须与之前调用 CommitIndex 任务提供的 commitName 值匹配。</td>
    </tr>
    <tr>
      <td>CommitIndex</td>
      <td>在当前打开的 IndexWriter 上调用 commit() 方法。要求 IndexWriter 通过 CreateIndex 或 OpenIndex 任务打开。</td>
      <td><b>commitName</b>：一个记录到提交中字符串标签，可以之后通过 OpenIndex 任务打开指定的提交。</td>
    </tr>
    <tr>
      <td>CloseIndex</td>
      <td>关闭打开的索引</td>
      <td><b>doWait</b>：true 或者 false，如果为 false，IndexWriter 会终止任何运行中的合并操作，并强制关闭索引。这个参数是可选的，并且默认值为 true。</td>
    </tr>
    <tr>
      <td>OpenReader</td>
      <td>创建一个 IndexReader 和 IndexSearcher，对搜索任务可用。如果一个 Read 任务被调用，它将使用当前打开的 reader，如果没有 reader 打开，它会打开自己的 reader，执行它的任务，然后关闭它的 reader。这个任务用于多种场景的测试：共享 reader，在一个热 reader 上执行搜索，等等。</td>
      <td><b>commitName</b>：一个字符串标签，指定要打开哪个提交。这个参数值必须与之前调用 CommitIndex 任务提供的 commitName 值匹配。<br /><b>readOnly</b>：true 或者 false</td>
    </tr>
    <tr>
      <td>NearRealtimeReader</td>
      <td>创建一个后台线程定期（默认为 3.0 秒）醒来向当前 IndexWriter 请求近实时 reader。将花费了多长时间打印输出到 System.out。这个查询也运行一个固定查询 body:1，按 docdate 排序，并报告这个查询的执行好用多长的时间。</td>
      <td><b>pauseSec</b>：一个浮点值，指定间隔多长时间唤醒后台线程，去向 IndexWriter 请求近实时 reader</td>
    </tr>
    <tr>
      <td>FlushIndex</td>
      <td>利用 IndexWriter.flushNextBuffer() 刷新线程级的文档。</td>
      <td></td>
    </tr>
    <tr>
      <td>CloseReader</td>
      <td>关闭之前打开的 reader</td>
      <td></td>
    </tr>
    <tr>
      <td>NewAnalyzer</td>
      <td>创建新的分析器，并把它设置到 getRunData() 中，可以被未来的其它任务使用。这个任务使用单个的参数，是一个逗号分隔的类名列表。每次这个任务被执行，它会在列表中选择下一个类，创建新的分析器。到列表结尾时，它回转到列表开头，再次轮回创建。</td>
      <td></td>
    </tr>
    <tr>
      <td>Search</td>
      <td>对索引执行搜索。如果 reader 已经打开（通过 OpenReader 任务），直接搜索。否则，打开一个新的 reader，执行搜索，然后关闭 reader。这个任务简单的执行搜索，但不访问搜索结果</td>
      <td></td>
    </tr>
    <tr>
      <td>SearchWithSort</td>
      <td>使用指定的排序执行搜索</td>
      <td><b>sortField</b>：逗号分隔的 field:type 对字符串列表，格式为 field:type,field:type[,noscore][,nomaxscore]。例如，"country:string,sort_field:int"。doc 意味着通过 Lucene 的 docID 排序；noscore 含义是不计算结果评分；nomaxscore 的含义是不计算最大评分值</td>
    </tr>
    <tr>
      <td>SearchTrav</td>
      <td>对索引执行搜索，并对搜索结果进行遍历访问。与 Search 任务类似，除了访问 top n 的 ScoreDoc。该任务带有一个可选的整数类型参数，是访问 ScoreDoc 的数量。如果该参数没有指定，则整个结果集都被访问。这个任务返回它访问的文档的数量。</td>
      <td><b>traversalSize</b>：整数型数值，指定访问多少个 top n ScoreDoc 搜索结果</td>
    </tr>
    <tr>
      <td>SearchTravRet</td>
      <td>对索引执行搜索并遍历结果，以及搜索结果进行检索。与 SearchTrav 类似，另外访问每个 ScorDoc，并从索引中检索对应的文档。</td> 
      <td><b>traversalSize</b>：整数型数值，指定访问多少个 top n ScoreDoc 搜索结果</td>
    </tr>
    <tr>
      <td>SearchTravRetLoadFieldSelector</td>
      <td>搜索索引，遍历结果、只对搜索结果中指定的域进行检索。与 SearchTrav 类似，另外该任务带有一个可选的逗号分隔的字符串参数，指定在搜索结果中，对文档的哪些域进行检索。</td>
      <td><b>fieldsToLoad </b>：逗号分隔的字符串列表，指定在搜索结果中，对文档的哪些域进行检索</td>
    </tr>
    <tr>
      <td>SearchTravRetHighlight</td>
      <td>搜索索引，并对搜索结果进行遍历、检索。对被检索文档的某些域进行高亮显示</td>
      <td><b>highlightDesc </b>：可选的、多值的、逗号分隔字符串参数，格式为：type[<enum>],maxFrags[<int>],fields[name1;name2;...]。参考 JavaDoc 了解参数各部分详情。</td>
    </tr>
    <tr>
      <td>SetProp</td>
      <td>改变属性值。一般情况下，属性的值在算法脚本第一次载入时设置一次。这个任务可以在流程中间改变属性值。所有在这个任务之后执行的任务，都能看到这个新的值。</td>
      <td><b>propertyName,value</b>：以 "name,value" 对形式字符串给配置属性设置新值。</td>
    </tr>
    <tr>
      <td>Warm</td>
      <td>通过检索索引中全部的文档来对之前打开的 searcher 进行预处理（warm up）。注意，在实际的应用程序中，这种处理不够充分的，因为如果正在使用 DocValues，还需要对 DocValues 进行预处理，并且可能还要对常用词项的搜索进行初始化。另外一种选择是，可以在算法脚本中创建几个步骤，来简化运行自己的查询序列，作为自定义的预处理。</td>
      <td></td>
    </tr>
    <tr>
      <td>AddDoc</td>
      <td>向索引中添加下一个文档。IndexWriter 必须已经打开。</td>
      <td><b>docSize </b>：数值型参数，指定加入索引文档的大小，以字符为单位。从内容源获取每个文档的主体（body）内容，要在这个参数指定的大小位置截断，剩余的部分将被放置在下一个文档的主体内容的前部。要求文档构建器 doc maker 支持改变文档大小。</td>
    </tr>
    <tr>
      <td>UpdateDoc</td>
      <td>调用 IndexWriter.updateDocument() 方法替换索引中的文档。新替换文档的 docid 域通过 Term 对象传递，指明哪个文档需要被更新。doc.random.id.limit 属性，控制随机分配的 docID 范围，在测试 updateDocument() 方法时非常实用。</td>
      <td><b>docSize </b>：含义与 AddDoc 相同。</td>
    </tr>
    <tr>
      <td>ReadTokens</td>
      <td>这个任务测试分析器中只是分词器的性能。简单地从文档构建器 doc maker 中读取下一个文档，并对文档中全部的域进行完全分词。作为计数器，这个任务返回处理的词元数量。这对衡量文档检索和分词开销是个很有用的任务。从构建索引所用的时间开销，减去这个时间开销，可以得到实际索引时间开销的粗略估算。</td>
      <td></td>
    </tr>
    <tr>
      <td>WriteLineDoc</td>
      <td>创建一个按行分隔文档的文件，一行表示一个文档。参考下一节的阐述。</td>
      <td><b>docSize </b>：含义与 AddDoc 相同。</td>
    </tr>
    <tr>
      <td>Wait</td>
      <td>简单地等待指定数量的时间。这个任务在有一定数量的优先任务正在后台运行（通过 & 符号表示）时，很有用。</td>
      <td><b>waitTime</b>：等待的时长，数值结尾可带有 's'、'm'、'h' 表示时长的单位为秒钟、分钟、小时。</td>
    </tr>
    <tr>
      <td></td>
      <td></td>
    </tr>
</table>


<br/><br/>
<a id="1"></a>

## 9.4.1 创建和使用行文件 Creating and using line files ##

行文件是简单的文本文件，每一行包含一个文档。从一个行文件索引文档导致比从其他方式索引文件少一些开销，比如每一个文档都需要打开然后关闭一个文件这种形式，或者从数据库中获取文件，或者解析 XML 文件。如果正在尝试衡量只是核心索引操作的性能，最小化这个开销是非常重要的。而如果尝试衡量从某一特定内容源进行索引的性能，那么就不应该使用一个行文件进行测试。

benchmark 模块框架提供了一个简单的 WriteLineDoc 任务，它用于创建从任何内容源创建行文件。使用这个任务，可以将任何数据源转换为一个行文件。一个限制是，每个文档只有标题 title，日期 date，内容主体 body 这三个域，其间由 `<TAB>` 键分隔。每一行的格式为：

```perl
title <TAB> date <TAB> body
```

支持下面几个属性参数：

- **line.file.out**：WriteLineDoc 任务要写出的文件名。这个参数是强制性的，注意，如果指定的文件已存在，则该文件会被重建。
- **line.fields**：每一行要写入哪些域。这个选项是可选的，默认为 DEFAULT_FIELDS，即 "doctitle,docdate,body"。可以自定义指定不同的域名称。
- **sufficient.fields**：域名字列表，由逗号分隔，如果都不存在，文档会被忽略。例如，要求至少 f1,f2 其中一个不为空，则这个属性设置 "f1,f2"。要指定没有域是必须的，例如，即使是空文档也被输出，指定的参数为 ","。这个参数是可选的，默认值为 DEFAULT_SUFFICIENT_FIELDS，即 "doctitle,body"。

输出文件的格式根据输出文件扩展名设置，即由 line.file.out 属性设置指定的输出文件名。如果预期的文件非常庞大，建议使用压缩格式。文件扩展名与输出文件格式的对应关系通过 StreamUtils.Type 枚举类型定义，如下所示：

- **BZIP2**：对应文件扩展名 .bz2 和 .bzip2，自动使用 BZIP2 压缩。
- **GZIP**: 对应文件扩展名 .gz 和 .gzip，自动使用 GZIP 压缩。
- **PLAIN**：除了 BZIP2 和 GZIP 压缩对应的文件扩展名，其它都使用纯文本格式输出文件。

注意，这个任务类是非线程安全的，如果在多线程环境下使用，输出文件内容是无法预料的。

示例，使用算法文件将路透社文件转换为单行文件：

```perl
# Where to get documents from:
content.source=org.apache.lucene.benchmark.byTask.feeds.ReutersContentSource

# Stop after processing the document feed once:
content.source.forever=false

# Where to write the line file output:
line.file.out=work/reuters.lines.txt

# Process all documents, appending each one to the line file:
{WriteLineDoc}: *

```

运行完这个算法脚本之后，然后就可以利用产生的 reuters.lines.txt 文件和 LineDocSource 任务执行下面的操作：

```perl
# Feed that knows how to process the line file format:
content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource

# File that contains one document per line:
docs.file=work/reuters.lines.txt

# Process documents only once:
content.source.forever=false

# Create a new index, index all docs from the line file, close the
# index, produce a report.
CreateIndex
{AddDoc}: *
CloseIndex

RepSumByPref AddDoc

```

<br/><br/>
<a id="2"></a>

## 9.4.2 内置的报告任务 Built-in reporting tasks ##

报告任务在算法脚本的结束位置生成总结报告，显示每秒完成多少个记录，使用了多少内存，收集的每个任务或任务序列统计信息显示为一行。不对报告任务本身进行衡量或生成报告。表 9.8 描述了内置的报告任务。如果需要，可以通过继承抽象类 ReportTask，并操纵 Points 和 TaskStats 中的统计信息，来实现自定义报告任务。

<div>表 9.8 内置的报告任务 reporting tasks</div>

<table width="100%">
    <tr bgcolor=#AA0000>
        <th align=center>任务名</th>
        <th align=center>说明</th>
    </tr>
    <tr>
      <td>RepAll</td>
      <td>报告全部统计信息，不进行聚合计算</td>
    </tr>
    <tr>
      <td>RepSumByName</td>
      <td>通过名称聚合全部统计信息。因此，如果 AddDoc 任务被执行 2000 次，只为其创建一行的报告，聚合全部的 2000 个统计记录。</td>
    </tr>
    <tr>
      <td>RepSelectByPref prefix</td>
      <td>报告名称以 prefix 前缀开始任务的全部记录，不进行聚合计算</td>
    </tr>
    <tr>
      <td>RepSumByPref prefix</td>
      <td>对名称以 prefix 前缀开始任务的全部记录，通过完全任务名称进行聚合计算</td>
    </tr>
    <tr>
      <td>RepSumByNameRound</td>
      <td>全部统计信息，按名称和轮次聚合。因此，在三个轮次的运行中，如果每一轮次的运行，AddDoc 任务被执行 2000 次，则会创建三个报告行，在每一个报告行中，对每一轮次运行全部 2000 个统计记录执行聚合计算</td>
    </tr>
    <tr>
      <td>RepSumByPrefRound prefix</td>
      <td>与 RepSumByNameRound 任务类似，只是只有名称以 prefix 前缀开始的任务被包括到统计聚合计算。</td>
    </tr>
</table>





