## 9.1 运行算法 Running an algorithm ##

将下面代码保存为一个 UTF-8 编码的算法脚本文件 test.alg:

```perl
# The analyzer to use
analyzer=org.apache.lucene.analysis.standard.StandardAnalyzer

# Content source
content.source=org.apache.lucene.benchmark.byTask.feeds.ReutersContentSource

work.dir=G:\\dev\\book\\benchmark-work
docs.dir=G:\\dev\\book\\benchmark-work\\reuters-out

# Directory
directory=FSDirectory

# Turn on stored fields
doc.stored = true

# Turn on term vectors
doc.term.vectors = true

# Don't use compound-file format
compound = false

# Make only one pass through the documents
content.source.forever = false

# Repeat 3 times
{"Rounds"
    # Clear the index
    ResetSystemErase

    # Name the contained tasks "BuildIndex"
    {"BuildIndex"

        # Create a new IndexWriter
        -CreateIndex

        # Add all docs
        { "AddDocs" AddDoc > : 21578

        # Close the index
        -CloseIndex
    }
    # Start a new round
    NewRound
} : 3

# Report on the BuildIndex task
RepSumByPrefRound BuildIndex

```

可能已经猜到，这个算法对整个路透社文集（Reuters corpus）进行索引，重复三次，并对每一次运行分别报告 BuildIndex 步骤的性能。这些步骤包括创建新索引（打开 IndexWriter），向索引库中添加全部的路透社文档，以及关闭该索引。记住，在测试索引操作性能时，包括关闭索引所用的时间是很重要的，因为任务在调用 IndexWriter 的 close()方法关闭索引时，会发生必要的时间消耗。例如，Lucene 会等待仍在后台运行的合并操作结束，并将所有新写入的文件同步到索引库。

Lucene 8 及以下版本 benchmark 使用 Lucene 项目的 Ant 预定义 run-task 目标运行（注意，Lucene 9 改由 Gradle 构建，不能使用本文所述的方法运行 benchmark，需要使用 gradle 或 gradlw 命令运行 benchmark）。需要下载 Lucene 项目对应本书版本的源码包：https://archive.apache.org/dist/lucene/java/8.11.2/lucene-8.11.2-src.tgz。 解压后进入到 benchmark 目录下，其中模块构建文件 build.xml 中定义了 run-task 目标，该目标通过一个 ant java 任务，执行 org.apache.lucene.benchmark.byTask.Benchmark 模块的执行 Main 类。run-task 目标依赖 compile,check-files,get-files 目标，需要两个属性值：算法文件 task.alg 和内存使用量 task.mem。

其中 task.alg 作为 main 函数的参数传递给 Benchmark 类。benchmark 模块的 conf 目录预定义了大量算法文件，用于定义各种性能测试所需配置的算法文件，run-task 目标默认使用 conf/micro-standard.alg 算法文件。

task.mem 作为 maxmemory 特性值传递给 ant java 任务，因为 java 任务的 fork 参数设为 "true"，另外启动一个 JVM 运行 Benchmark 任务，这个特性值就是为新启动的 JVM 分配内存的大小，默认 140M。

在 benchmark 目录下，使用下面的命令运行自定义算法：

```shell
ant run-task -Dtask.alg=<file.alg> -Dtask.mem=512M
```

注意，如果实现了自定义的任务，必须也要把编译出的类加入到 Ant 命令行的类路径，通过如下命令行参数指定：

```shell
-Dbenchmark.ext.classpath=/path/to/classes
```

benchmark.ext.classpath 是 id 为 "run.classpath" 的 path 元素内包含的一个 pathelement 子元素，默认是未定义的。要使用自定义任务类，就通过该参数向 ant 传递类路径。"run.classpath" path 被 run-task 目标作为 classpath 元素引用。

完整的 benchmark 运行命令如下：

```shell
ant run-task -Dtask.alg=[full-path-to-your-alg-file] -Dbenchmark.ext.classpath=/mydir/classes -Dtask.mem=512M
```

ant 的 run-task 目标首先运行一系列的依赖目标，例如，确保所有的源代码都被编译完成并下载，然后对路透社文集进行解压。

我们将处理好的路透社文件放到我们算法文件制定的目录下：docs.dir=G:\\dev\\book\\benchmark-work\\reuters-out

然后运行我们的算法文件进行性能测试：

```shell
ant run-task -Dtask.alg=G:\\dev\\book\\lucene8\\benchmark\\test.alg -Dtask.mem=1024M

```

ant 通过 run-task 目标运行带有 main 函数的 org.apache.lucene.benchmark.byTask.Benchmark 任务类并产生类似下面的输出：

```shell
run-task:
     [echo] Working Directory: G:\dev\book\lucene-8.11.2\benchmark\work
     [java] Running algorithm from: G:\dev\book\lucene8\benchmark\test.alg
     [java] ------------> config properties:
     [java] analyzer = org.apache.lucene.analysis.standard.StandardAnalyzer
     [java] compound = false
     [java] content.source = org.apache.lucene.benchmark.byTask.feeds.ReutersContentSource
     [java] content.source.forever = false
     [java] directory = FSDirectory
     [java] doc.stored = true
     [java] doc.term.vectors = true
     [java] docs.dir = G:\dev\book\benchmark-work\reuters-out
     [java] work.dir = G:\dev\book\benchmark-work
     [java] -------------------------------
     [java] ------------> algorithm:
     [java] Seq {
     [java]     Rounds_3 {
     [java]         ResetSystemErase
     [java]         BuildIndex {
     [java]             -CreateIndex
     [java]             AddDocs_21578 {
     [java]                 AddDoc
     [java]             > * 21578
     [java]             -CloseIndex
     [java]         }
     [java]         NewRound
     [java]     } * 3
     [java]     RepSumByPrefRound BuildIndex
     [java] }
     [java]
     [java] ------------> starting task: Seq
     [java]    1.22 sec --> main added      1000 docs
     [java]    1.86 sec --> main added      2000 docs
     [java]    2.43 sec --> main added      3000 docs
     [java]    2.94 sec --> main added      4000 docs
     [java]    3.44 sec --> main added      5000 docs
     [java]    3.95 sec --> main added      6000 docs
     [java]    4.45 sec --> main added      7000 docs
     [java]    4.95 sec --> main added      8000 docs
     [java]    5.44 sec --> main added      9000 docs
     [java]    5.92 sec --> main added     10000 docs
     [java]    6.40 sec --> main added     11000 docs
     [java]    6.88 sec --> main added     12000 docs
     [java]    7.36 sec --> main added     13000 docs
     [java]    7.82 sec --> main added     14000 docs
     [java]    8.27 sec --> main added     15000 docs
     [java]    8.76 sec --> main added     16000 docs
     [java]    9.27 sec --> main added     17000 docs
     [java]    9.78 sec --> main added     18000 docs
     [java]   10.29 sec --> main added     19000 docs
     [java]   10.77 sec --> main added     20000 docs
     [java]   11.24 sec --> main added     21000 docs
     [java]
     [java] --> Round 0-->1
     [java]
     [java]    0.33 sec --> main added     22000 docs
     [java]    0.90 sec --> main added     23000 docs
     [java]    1.38 sec --> main added     24000 docs
     [java]    1.85 sec --> main added     25000 docs
     [java]    2.33 sec --> main added     26000 docs
     [java]    2.82 sec --> main added     27000 docs
     [java]    3.32 sec --> main added     28000 docs
     [java]    3.80 sec --> main added     29000 docs
     [java]    4.29 sec --> main added     30000 docs
     [java]    4.78 sec --> main added     31000 docs
     [java]    5.28 sec --> main added     32000 docs
     [java]    5.77 sec --> main added     33000 docs
     [java]    6.26 sec --> main added     34000 docs
     [java]    6.74 sec --> main added     35000 docs
     [java]    7.20 sec --> main added     36000 docs
     [java]    7.67 sec --> main added     37000 docs
     [java]    8.15 sec --> main added     38000 docs
     [java]    8.65 sec --> main added     39000 docs
     [java]    9.14 sec --> main added     40000 docs
     [java]    9.62 sec --> main added     41000 docs
     [java]   10.08 sec --> main added     42000 docs
     [java]   10.54 sec --> main added     43000 docs
     [java]
     [java] --> Round 1-->2
     [java]
     [java]    0.41 sec --> main added     44000 docs
     [java]    0.87 sec --> main added     45000 docs
     [java]    1.35 sec --> main added     46000 docs
     [java]    1.83 sec --> main added     47000 docs
     [java]    2.30 sec --> main added     48000 docs
     [java]    2.79 sec --> main added     49000 docs
     [java]    3.26 sec --> main added     50000 docs
     [java]    3.75 sec --> main added     51000 docs
     [java]    4.24 sec --> main added     52000 docs
     [java]    4.72 sec --> main added     53000 docs
     [java]    5.20 sec --> main added     54000 docs
     [java]    5.69 sec --> main added     55000 docs
     [java]    6.17 sec --> main added     56000 docs
     [java]    6.64 sec --> main added     57000 docs
     [java]    7.10 sec --> main added     58000 docs
     [java]    7.59 sec --> main added     59000 docs
     [java]    8.08 sec --> main added     60000 docs
     [java]    8.58 sec --> main added     61000 docs
     [java]    9.06 sec --> main added     62000 docs
     [java]    9.54 sec --> main added     63000 docs
     [java]   10.01 sec --> main added     64000 docs
     [java]
     [java] --> Round 2-->3
     [java]
     [java]
     [java] ------------> Report sum by Prefix (BuildIndex) and Round (3 about 3 out of 14)
     [java] Operation   round   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem
     [java] BuildIndex      0        1        21578     1,671.42       12.91    56,432,320     79,691,776
     [java] BuildIndex -  - 1 -  -   1 -  -   21578 -   1,802.67 -  -  11.97 -  53,957,448 -   81,788,928
     [java] BuildIndex      2        1        21578     1,866.61       11.56    48,189,512     81,788,928
     [java]
     [java] ####################
     [java] ###  D O N E !!! ###
     [java] ####################

BUILD SUCCESSFUL
Total time: 48 seconds

```

benchmark 模块首先在 config properties: 区域打印出运行的全部配置信息。最好仔细检查并验证这些设置与我们所期望的一致。接下来，它用格式打印（pretty-prints）的方式打印出算法的各个步骤，algorithm: 下面的部分。也应该验证打印出的算法与我们所期望的一致。如果将一个结束大括号 } 放在了错误的位置上，在这里会立即注意到它。最后，benchmark 运行算法并将状态输出打印出来，通常由如下的信息组成：

- 内容源每一轮次打印产生了多少文档
- Round 任务在其结束每一轮运行时打印其统计信息

在整个任务结束时，并且假如在算法中有报告任务，会生成最终报告，输出每一轮运行的详细指标信息。

因为我们使用了 RepSumByPrefRound 报告任务，将统计结果按每一轮划分，因此最终报告每轮任务的执行显示在一行内。对于每一轮任务的执行，它包括记录的数量（本例是添加文档的数量）recsPerRun，每秒记录数 rec/s，耗费的时间秒数 elapsedSec，以及使用内存量 avgUsedMem。平均内存总数 avgTotalMem 是通过调用 java.lang.Runtime.getRuntime().totalMemory() 方法获得的。平均使用的内存量 avgUsedMem 是通过 totalMemory() 减去 freeMemory() 计算得来的。

&emsp;&emsp;什么是准确的记录呢？通常，在记录的计数上，多数的任务计数为 +1。例如，每次调用 AddDoc 任务时，都会给该任务的记录计数加 1。任务序列（Task sequences）聚合其子任务的全部记录计数。为了阻止记录计数的增长操作，可以在任务名之前加一个连字符（-），就如在上面算法文件中对 CreateIndex 和 CloseIndex 任务所做的那样：

```perl
    # Create a new IndexWriter
    -CreateIndex
    
    ...

    # Close the index
    -CloseIndex
```

这样做将创建和关闭索引的开销（时间和内存）包含进来，并能正确地分摊到全部添加文档的总体开销中。

&emsp;&emsp;如果不想每次运行基线测试都使用 Lucene 源代码来执行，可以按照 benchmark 目录下的 build.xml 文件思路，创建一个自己的 ant 项目，并编写自定义的 build.xml 文件执行基线测试。










